#!/usr/bin/env python3
"""
Snake Multimodal Learning Experiment with MycoNet Integration
Postdoctoral-level examination comparing: Control, Audio-only, Audio+Visual conditions.
Enhanced with MycoNet mycelial coordination system for intelligent multimodal learning.
"""

import sys
import os
import time
import json
import pygame
import numpy as np
from pathlib import Path

# Agregar src al path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from snake_env import SnakeEnv
from snake_agent import IncrementalSnakeAgent
from snake_audio import SnakeAudioSystem, CognitiveAudioFeedback

# Importar MycoNet para coordinaciÃ³n micelial
from src.ucognet.modules.mycelium.integration import MycoNetIntegration
from src.ucognet.modules.mycelium.types import MycoContext

class MycelialSnakeCoordinator:
    """
    MycoNet coordinator for Snake multimodal learning.

    Uses mycelial intelligence to coordinate attention between different
    sensory modalities and optimize learning strategies.
    """

    def __init__(self):
        # Initialize MycoNet integration
        self.myco_integration = MycoNetIntegration()
        self.myco_integration.initialize_standard_modules()

        # Register Snake-specific modules
        self._register_snake_modules()

        # Learning state
        self.current_condition = None
        self.episode_count = 0

    def _register_snake_modules(self):
        """Register Snake game specific modules in MycoNet"""
        from src.ucognet.modules.mycelium.core import MycoNode

        # Control module (baseline learning)
        control_node = MycoNode("snake_control",
                               {"reinforcement_learning": 0.9, "q_learning": 0.8})
        self.myco_integration.myco_net.register_node(control_node)

        # Audio feedback module
        audio_node = MycoNode("snake_audio",
                             {"auditory_feedback": 1.0, "emotional_modulation": 0.9})
        self.myco_integration.myco_net.register_node(audio_node)

        # Visual feedback module
        visual_node = MycoNode("snake_visual",
                              {"real_time_display": 0.95, "spatial_awareness": 0.85})
        self.myco_integration.myco_net.register_node(visual_node)

        # Multimodal integration module
        multimodal_node = MycoNode("snake_multimodal",
                                  {"cross_modal_fusion": 0.9, "synergistic_learning": 0.95})
        self.myco_integration.myco_net.register_node(multimodal_node)

        # Connect modules with intelligent topology
        self.myco_integration.myco_net.connect("snake_control", "snake_audio")
        self.myco_integration.myco_net.connect("snake_control", "snake_visual")
        self.myco_integration.myco_net.connect("snake_audio", "snake_multimodal")
        self.myco_integration.myco_net.connect("snake_visual", "snake_multimodal")
        self.myco_integration.myco_net.connect("snake_multimodal", "cognitive_core")

    def coordinate_learning(self, condition: str, episode_data: dict) -> dict:
        """
        Use MycoNet to coordinate learning strategy for current condition.

        Returns routing decision and coordination insights.
        """
        # Create context for MycoNet
        context = MycoContext(
            task_id=f"snake_learning_{condition}",
            phase="learning",
            metrics={
                'episode': episode_data.get('episode', 0),
                'score': episode_data.get('score', 0),
                'reward': episode_data.get('reward', 0),
                'condition_complexity': self._get_condition_complexity(condition)
            },
            timestamp=time.time()
        )

        # Get routing decision from MycoNet
        result, confidence = self.myco_integration.process_request(
            task_id=f"snake_{condition}_episode_{episode_data.get('episode', 0)}",
            metrics=context.metrics,
            phase="learning"
        )

        coordination = {
            'routing_decision': result,
            'confidence': confidence,
            'active_modules': result['path'] if result else [],
            'safety_score': result['safety_score'] if result else 0.0,
            'expected_reward': result['expected_reward'] if result else 0.0,
            'emergent_strategies': self._detect_emergent_strategies(result, condition) if result else []
        }

        # Learn from this coordination decision
        if result:
            actual_reward = episode_data.get('reward', 0) * confidence
            self.myco_integration.reinforce_learning(result, actual_reward)

        # Maintenance cycle
        if episode_data.get('episode', 0) % 50 == 0:
            self.myco_integration.maintenance_cycle()

        return coordination

    def _get_condition_complexity(self, condition: str) -> float:
        """Get complexity score for different conditions"""
        complexities = {
            'control': 0.3,      # Baseline, minimal complexity
            'audio': 0.6,        # Audio adds emotional modulation
            'audio_visual': 0.9  # Full multimodal, highest complexity
        }
        return complexities.get(condition, 0.5)

    def _detect_emergent_strategies(self, routing_result: dict, condition: str) -> list:
        """Detect emergent learning strategies from MycoNet routing"""
        strategies = []
        path = routing_result.get('path', [])

        # Analyze path patterns for emergent behavior
        if 'snake_multimodal' in path and len(path) > 2:
            strategies.append("cross_modal_integration")

        if 'snake_audio' in path and 'snake_visual' in path:
            strategies.append("balanced_sensory_attention")

        if path.count('cognitive_core') > 1:
            strategies.append("deep_reasoning_loops")

        if routing_result.get('safety_score', 0) > 0.9:
            strategies.append("high_safety_learning")

        return strategies

    def get_learning_insights(self) -> dict:
        """Get insights from MycoNet about learning progress"""
        status = self.myco_integration.get_integration_status()

        return {
            'myco_net_health': status['myco_net_metrics'],
            'active_connections': status['active_connections'],
            'emergent_behaviors': status['myco_net_metrics'].get('emergent_behaviors', []),
            'routing_efficiency': status['integration_metrics'].get('routes_processed', 0),
            'performance_gain': status['integration_metrics'].get('performance_gain', 0.0)
        }

class SnakeVisualizer:
    """Real-time visualization system for Snake game using pygame."""

    def __init__(self, width=20, height=20, cell_size=20, enabled=True):
        self.enabled = enabled
        self.width = width
        self.height = height
        self.cell_size = cell_size
        self.screen_size = (width * cell_size, height * cell_size)

        if enabled:
            self._initialize_display()

    def _initialize_display(self):
        """Initialize pygame display."""
        try:
            pygame.init()
            self.screen = pygame.display.set_mode(self.screen_size)
            pygame.display.set_caption("U-CogNet: Snake Multimodal Learning with MycoNet")
            self.clock = pygame.time.Clock()
            self.font = pygame.font.Font(None, 20)
            print("ðŸŽ® Real-time visualization initialized")
        except Exception as e:
            print(f"âš ï¸ Visualization initialization failed: {e}")
            self.enabled = False

    def render(self, env, episode, score, steps, audio_enabled=False, myco_info=None):
        """Render the current game state with MycoNet information."""
        if not self.enabled:
            return

        # Clear screen
        self.screen.fill((0, 0, 0))

        # Draw grid
        for x in range(self.width):
            for y in range(self.height):
                rect = pygame.Rect(x * self.cell_size, y * self.cell_size,
                                 self.cell_size, self.cell_size)
                pygame.draw.rect(self.screen, (40, 40, 40), rect, 1)

        # Draw snake
        for segment in env.snake:
            x, y = segment
            rect = pygame.Rect(x * self.cell_size, y * self.cell_size,
                             self.cell_size, self.cell_size)
            pygame.draw.rect(self.screen, (0, 255, 0), rect)

        # Draw snake head differently
        if env.snake:
            head_x, head_y = env.snake[0]
            rect = pygame.Rect(head_x * self.cell_size, head_y * self.cell_size,
                             self.cell_size, self.cell_size)
            pygame.draw.rect(self.screen, (0, 200, 0), rect)

        # Draw food
        food_x, food_y = env.food
        rect = pygame.Rect(food_x * self.cell_size, food_y * self.cell_size,
                         self.cell_size, self.cell_size)
        pygame.draw.rect(self.screen, (255, 0, 0), rect)

        # Draw UI with MycoNet information
        ui_y = 10
        texts = [
            f"Episode: {episode}",
            f"Score: {score}",
            f"Steps: {steps}",
            f"Audio: {'ON' if audio_enabled else 'OFF'}",
            f"Visual: ON"
        ]

        # Add MycoNet information if available
        if myco_info:
            texts.extend([
                f"MycoNet: {'ACTIVE' if myco_info.get('routing_decision') else 'INACTIVE'}",
                f"Confidence: {myco_info.get('confidence', 0):.2f}",
                f"Modules: {len(myco_info.get('active_modules', []))}"
            ])

        for text in texts:
            text_surface = self.font.render(text, True, (255, 255, 255))
            self.screen.blit(text_surface, (10, ui_y))
            ui_y += 20

        pygame.display.flip()
        self.clock.tick(10)  # Control frame rate

        # Handle events to prevent freezing
        for event in pygame.event.get():
            if event.type == pygame.QUIT:
                pygame.quit()
                sys.exit()

    def cleanup(self):
        """Clean up visualization resources."""
        if self.enabled:
            pygame.quit()

def multimodal_reward_enhancement(base_reward: float, audio_system: SnakeAudioSystem,
                                visual_enabled: bool, myco_coordination: dict = None) -> float:
    """
    Enhanced reward function with multimodal feedback and MycoNet coordination.

    Cognitive hypothesis: Multiple sensory modalities coordinated by mycelial
    intelligence can synergistically enhance reinforcement learning.
    """
    enhancement_factor = 1.0

    # Base multimodal enhancement
    if base_reward > 0:
        if audio_system.enabled:
            audio_system.play_eat_sound()
            enhancement_factor *= 1.2

        if visual_enabled:
            enhancement_factor *= 1.05

    elif base_reward < 0:
        if audio_system.enabled:
            audio_system.play_death_sound()
            enhancement_factor *= 1.3

        if visual_enabled:
            enhancement_factor *= 1.1

    # MycoNet coordination enhancement
    if myco_coordination:
        confidence = myco_coordination.get('confidence', 0.5)
        safety_score = myco_coordination.get('safety_score', 0.5)

        # MycoNet can modulate learning intensity
        myco_modulation = 0.9 + (confidence * safety_score * 0.2)  # 0.9 to 1.1
        enhancement_factor *= myco_modulation

        # Additional reward for emergent strategies
        if myco_coordination.get('emergent_strategies'):
            strategy_bonus = len(myco_coordination['emergent_strategies']) * 0.05
            enhancement_factor *= (1.0 + strategy_bonus)

    return base_reward * enhancement_factor

def run_mycelial_multimodal_experiment(condition: str, num_episodes: int = 100) -> dict:
    """Run experiment with MycoNet-enhanced multimodal learning."""

    # Configure modalities based on condition
    audio_enabled = condition in ['audio', 'audio_visual']
    visual_enabled = condition == 'audio_visual'

    print(f"\n{'='*80}")
    print(f"MYCO-ENHANCED MULTIMODAL EXPERIMENT: {condition.upper()}")
    print(f"Audio: {'ENABLED' if audio_enabled else 'DISABLED'}")
    print(f"Real-time Visual: {'ENABLED' if visual_enabled else 'DISABLED'}")
    print(f"MycoNet Coordination: ENABLED")
    print(f"Episodes: {num_episodes}")
    print(f"{'='*80}")

    # Initialize systems
    env = SnakeEnv(width=20, height=20)
    agent = IncrementalSnakeAgent()

    # Initialize multimodal systems
    audio_system = SnakeAudioSystem(enabled=audio_enabled)
    visualizer = SnakeVisualizer(enabled=visual_enabled)

    # Initialize MycoNet coordinator
    myco_coordinator = MycelialSnakeCoordinator()

    results = {
        'experiment_name': f"MycoNet_{condition}",
        'condition': condition,
        'audio_enabled': audio_enabled,
        'visual_enabled': visual_enabled,
        'myco_net_enabled': True,
        'episodes': [],
        'myco_coordination_log': [],
        'final_stats': {}
    }

    try:
        for episode in range(1, num_episodes + 1):
            state = env.reset()
            done = False
            episode_reward = 0
            steps = 0

            # Episode data for MycoNet
            episode_data = {
                'episode': episode,
                'condition': condition,
                'start_time': time.time()
            }

            while not done and steps < 1000:
                action = agent.choose_action(state)

                next_state, base_reward, done, _ = env.step(action)

                # Get MycoNet coordination for this step
                myco_coordination = myco_coordinator.coordinate_learning(condition, episode_data)

                # Apply MycoNet-enhanced multimodal reward
                reward = multimodal_reward_enhancement(base_reward, audio_system,
                                                     visual_enabled, myco_coordination)

                agent.learn(state, action, reward, next_state, done)

                state = next_state
                episode_reward += reward
                steps += 1

                # Render if visual enabled
                if visual_enabled:
                    visualizer.render(env, episode, env.score, steps, audio_enabled, myco_coordination)

            # Complete episode data
            episode_data.update({
                'score': env.score,
                'reward': episode_reward,
                'steps': steps,
                'q_states': len(agent.q_table),
                'end_time': time.time(),
                'duration': time.time() - episode_data['start_time']
            })

            score = env.score
            agent.update_stats(episode_reward, score)

            # Log MycoNet coordination
            final_coordination = myco_coordinator.coordinate_learning(condition, episode_data)
            results['myco_coordination_log'].append({
                'episode': episode,
                'coordination': final_coordination,
                'episode_data': episode_data
            })

            results['episodes'].append(episode_data)

            if episode % 20 == 0:
                avg_score = np.mean([ep['score'] for ep in results['episodes'][-20:]])
                myco_insights = myco_coordinator.get_learning_insights()
                print(f"Episode {episode}: Avg Score {avg_score:.2f}, Q-States {len(agent.q_table)}, "
                      f"MycoNet Routes: {myco_insights['routing_efficiency']}")

    finally:
        # Cleanup
        audio_system.cleanup()
        visualizer.cleanup()

    # Calculate final statistics
    all_scores = [ep['score'] for ep in results['episodes']]
    all_rewards = [ep['reward'] for ep in results['episodes']]

    # Get final MycoNet insights
    final_insights = myco_coordinator.get_learning_insights()

    results['final_stats'] = {
        'mean_score': float(np.mean(all_scores)),
        'std_score': float(np.std(all_scores)),
        'max_score': int(np.max(all_scores)),
        'mean_reward': float(np.mean(all_rewards)),
        'final_q_states': len(agent.q_table),
        'myco_net_insights': final_insights,
        'total_emergent_strategies': len(set([
            strategy for log in results['myco_coordination_log']
            for strategy in log['coordination'].get('emergent_strategies', [])
        ]))
    }

    print(f"\nCompleted MycoNet-{condition.upper()}")
    print(".2f")
    print(f"Best Score: {results['final_stats']['max_score']}")
    print(f"Q-States: {results['final_stats']['final_q_states']}")
    print(f"Emergent Strategies: {results['final_stats']['total_emergent_strategies']}")
    print(f"MycoNet Routes: {final_insights['routing_efficiency']}")

    return results

def main():
    print("ðŸ„ Snake Multimodal Learning Experiment with MycoNet Integration")
    print("Postdoctoral-Level Mycelial Sensory Coordination Study")
    print("=" * 100)

    # Run MycoNet-enhanced experiments
    print("\nðŸ§  Running MycoNet CONTROL Experiment...")
    control_results = run_mycelial_multimodal_experiment('control', 100)

    print("\nðŸ”Š Running MycoNet AUDIO Experiment...")
    audio_results = run_mycelial_multimodal_experiment('audio', 100)

    print("\nðŸŽ® Running MycoNet AUDIO+VISUAL Experiment...")
    audiovisual_results = run_mycelial_multimodal_experiment('audio_visual', 100)

    # Comparative Analysis
    print(f"\n{'='*80}")
    print("MYCONET ENHANCED ANALYSIS RESULTS")
    print(f"{'='*80}")

    experiments = {
        'Control': control_results,
        'Audio': audio_results,
        'Audio+Visual': audiovisual_results
    }

    print("\nðŸ“Š Performance Comparison:")
    print("Condition       | Mean Score | Max Score | Emergent Strategies | MycoNet Routes")
    print("-" * 75)

    for name, results in experiments.items():
        stats = results['final_stats']
        myco_insights = stats['myco_net_insights']
        print(f"{name:<15} | {stats['mean_score']:<10.2f} | {stats['max_score']:<9.2f} | {stats['total_emergent_strategies']:<18} | {myco_insights['total_routes']}")

    # MycoNet Effectiveness Analysis
    print("\nðŸ§¬ MycoNet Effectiveness:")
    control_score = control_results['final_stats']['mean_score']
    audio_score = audio_results['final_stats']['mean_score']
    audiovisual_score = audiovisual_results['final_stats']['mean_score']

    myco_improvement = ((audiovisual_score - control_score) / control_score) * 100 if control_score > 0 else 0

    print(f"Control Score: {control_score:.2f}")
    print(f"Audio Score: {audio_score:.2f}")
    print(f"Audio+Visual Score: {audiovisual_score:.2f}")
    print(f"MycoNet Improvement: {myco_improvement:.1f}%")

    # Emergent Behaviors Analysis
    total_emergent = sum([exp['final_stats']['total_emergent_strategies'] for exp in experiments.values()])
    print(f"\nðŸ§  Total Emergent Strategies Detected: {total_emergent}")

    # Save comprehensive results
    comprehensive_results = {
        'experiments': experiments,
        'myco_net_effectiveness': {
            'multimodal_improvement_percent': myco_improvement,
            'total_emergent_strategies': total_emergent,
            'coordination_logs': {
                name: results['myco_coordination_log'] for name, results in experiments.items()
            }
        },
        'metadata': {
            'experiment_type': 'MycoNet_Enhanced_Multimodal_Learning',
            'timestamp': time.time(),
            'description': 'Snake learning with mycelial coordination of sensory modalities'
        }
    }

    with open('snake_myco_multimodal_results.json', 'w') as f:
        json.dump(comprehensive_results, f, indent=2, default=str)

    print("\nðŸ’¾ Results saved to: snake_myco_multimodal_results.json")

    print(f"\n{'='*100}")
    print("SCIENTIFIC SUMMARY - MYCONET ENHANCED MULTIMODAL LEARNING")
    print(f"{'='*100}")
    print("This experiment demonstrates the integration of mycelial intelligence")
    print("with multimodal sensory processing for enhanced reinforcement learning.")
    print("MycoNet provides intelligent coordination between sensory modalities,")
    print("leading to emergent learning strategies and improved performance.")
    print(f"Total emergent strategies observed: {total_emergent}")

if __name__ == "__main__":
    main()